%/!\ /!\ 
%
% PLEASE DO NOT EDIT THIS IF YOU CAME HERE BY MISTAKE !!!!
%

% RTFMN : https://tobi.oetiker.ch/lshort/lshort.pdf

\documentclass{article}
\usepackage{xspace}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[francais]{babel}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{url}
\usepackage{amssymb}
\usepackage{latexsym}
\usepackage{mathrsfs}
\usepackage{amsfonts}
\usepackage{multicol}
\usepackage{stmaryrd}
\usepackage{tikz, pgf}
\usetikzlibrary{arrows,intersections}
\usepackage{libertine}
\usepackage{cancel}
\usepackage[a4paper,left=2cm,right=2cm,top=2cm,bottom=2cm]{geometry}
\usepackage{dsfont}


\usepackage[linktocpage]{hyperref}

\setlength{\hoffset}{-18pt}         
\setlength{\oddsidemargin}{15pt} % Marge gauche sur pages impaires
\setlength{\evensidemargin}{15pt} % Marge gauche sur pages paires
\setlength{\marginparwidth}{0pt} % Largeur de note dans la marge
\setlength{\textwidth}{481pt} % Largeur de la zone de texte 
\setlength{\marginparsep}{7pt} % Séparation de la marge
\setlength{\topmargin}{0pt} % Pas de marge en haut
\setlength{\headheight}{13pt} % Haut de page
\setlength{\headsep}{10pt} % Entre le haut de page et le texte
\setlength{\footskip}{50pt} % Bas de page + séparation
\setlength{\textheight}{600pt} % Hauteur de la zone de texte 

%\setlength{\hoffset}{-18pt}         
%\setlength{\oddsidemargin}{15pt} % Marge gauche sur pages impaires
%\setlength{\evensidemargin}{15pt} % Marge gauche sur pages paires
%\setlength{\marginparwidth}{0pt} % Largeur de note dans la marge
%\setlength{\textwidth}{481pt} % Largeur de la zone de texte 
%\setlength{\marginparsep}{7pt} % Séparation de la marge
%\setlength{\topmargin}{0pt} % Pas de marge en haut
%\setlength{\headheight}{8pt} % Haut de page
%\setlength{\headsep}{0pt} % Entre le haut de page et le texte
%\setlength{\footskip}{15pt} % Bas de page + séparation
%\setlength{\textheight}{700pt} % Hauteur de la zone de texte 

%\newcommand{\ket}[1]{\ensuremath{|#1\rangle}\xspace}
%\newcommand{\bra}[1]{\ensuremath{\langle #1|}\xspace}

\newtheorem{thm}{Théorème}[section]
\newtheorem{prop}[thm]{Proposition}
\newtheorem{lem}[thm]{Lemme}
\newtheorem{cor}[thm]{Corollaire}
\newtheorem{defi}[thm]{Définition}
\newtheorem{ex}[thm]{Exemple}

\newcommand{\Thm}[3]{\begin{thm}[#1]\label{#2}#3\end{thm}}
\newcommand{\Ex}[3]{\begin{ex}[#1]\label{#2}#3\end{ex}}
\newcommand{\Def}[3]{\begin{defi}[#1]\label{#2}#3\end{defi}}
\newcommand{\Lem}[3]{\begin{lem}[#1]\label{#2}#3\end{lem}}
\newcommand{\Cor}[3]{\begin{cor}[#1]\label{#2}#3\end{cor}}
\newcommand{\Prop}[3]{\begin{prop}[#1]\label{#2}#3\end{prop}}

\newcommand{\hsp}{\hspace{20pt}}
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\N}{\mathbb{N}}
\newcommand{\K}{\mathbb{K}}
\newcommand{\Q}{\mathbb{Q}}
\newcommand{\C}{\mathcal{C}}
\newcommand{\X}{\mathcal{X}}
\newcommand{\brakets}[1]{\langle#1\rangle}
\newcommand{\betaar}{\rightarrow_\beta}
\newcommand{\betar}{\twoheadrightarrow_\beta}
\newcommand{\alphaeq}{=_\alpha}
\newcommand{\rRule}[3]{\displaystyle\frac{#2}{#3}\ (\ensuremath{#1})} 

\newcommand{\ind}[1]{\mathds{1}_{#1}}

\title{Preuves et Programmes}
\author{Philippe Audebaud}
\date{Printemps 2017}



\begin{document}

\maketitle

\tableofcontents

\newpage

\section{ Lambda Calcul (pure)}
\subsection{Calculer avec des fonctions (uniquement)}
Main question : How do we do maths ? To answer that we can see:

\begin{itemize}
\item Having structures:
We want to manipulate numbers, spaces (of points, vectors and functions). (Eidenberg-Mac Lane, Category Theory, 1942). Those things will be the \underline{types}.

\item Build, explore and transform structures (Church's $\lambda$-calculus, 1930). Theses things with be programs, proofs.

\item Compare «stuff», with equality for instance (equality comes first !) (Voevaski, 2006, Algebraic Topology)

\item Provide a framework (rules) to reasoning on theses previous things.  This points is somehow the first point that comes when we want to do Maths.
\end{itemize}

One can notice that it is, in fact, basically, recent research.

\subsection{Introduction informelle au $\lambda$-calcul de Church} 

We take a function : $\begin{array}{l c c r}
f: & A & \rightarrow & B\\
& x & \mapsto & e
\end{array}$. Given $a\in A$, $f(a)$ is the image, we replace (kind of) each occurrence of $x$ in $e$ by an occurrence of $a$. Then we get $e\brakets{a/x}$. We say that we apply $f$ to $a$. We can denote $f\ a$ when there is no ambiguity. In terms of $\lambda$-calculus, we can define $f$ like that: $f\equiv \lambda x.e$ where $\equiv$ is the definitional equality. Then $f\ a\equiv (\lambda x.e)\ a$.

For the syntax, if there is no parenthesis, all what is after the $.$ is part of the body of the function.

\Ex{}{}{Here are some examples
\begin{itemize}
\item $\lambda x.x$ is the function $x\mapsto x$ is the identity function.
\item If $x$ and $y$ are two distinct variables the function $\lambda x.y$ as no effect since $y\brakets{a/x}\equiv y$ and then $(\lambda x.y)\ a \equiv y$.
\end{itemize}}

To «compute» terms we have to introduce a kind of reduction $\betaar$, a binary relation on $\lambda$-terms. For instance, $(\lambda x.a) b \betaar a\brakets{b/x}$.

Some terms also seems to be «equivalent». Then we may need some $\lambda$-equivalence, let say $\alphaeq$. For instance we would like to say when $y\neq x$ is a fresh variable that $\lambda x.e \alphaeq \lambda y.e\brakets{y/x}$. To state  $\lambda x.a \alphaeq \lambda y.b$, we might need some fresh variable $z$ such that $a\brakets{z/x}\alphaeq b\brakets{z/y}$.

\Def{}{}{On défini une égalité définitionnelle:
\begin{itemize}
\item si $t$ et $x$ sont des variables. $t\brakets{u/x}\equiv\left\{\begin{array}{r l}
u & \text{si $t=x$}\\
t & \text{sinon}
\end{array}\right.$
\item $(v\ w)\brakets{u/x}\equiv v\brakets{u/x}\ w\brakets{u/x}$
\item $(\lambda x.e)\brakets{u/y}\equiv\left\{\begin{array}{r l}
\lambda x.e\brakets{u/y} & \text{si $y\neq x$}\\
t & \text{sinon}
\end{array}\right.$
\end{itemize}}

\Def{$\alpha$-équivalence}{def:alphaEq}{On définit l'$\alpha$-équivalence comme ceci : $\forall z\notin FV(t), \lambda x.e \alphaeq \lambda z.e<z/x>$. Il s'agit en fait d'un renommage.}

\Ex{}{}{Ainsi $\lambda x.x\ y\alphaeq\lambda z.z y\neq_\alpha\lambda y. y\ y$.}

\subsection{Boite à outils concernant le $\lambda$-calcul.}
\subsubsection{Généralités}
Soit $\X$ en ensemble dénombrable variables, $x,y,z,...$.
\Def{$\lambda$-terms}{def:lterms}{Un $\lambda$-terme $e$ est généré par la grammaire suivante $e::= x\in\X | \lambda x.e | e e$. On note l'ensemble des $\lambda$-termes $\Lambda$.}

\Def{Variable libre}{def:freeVar}{L'ensemble des variables libres de $e$, noté $FV(e)$ est défini inductivement par:

\begin{itemize}
\item if $e = x\in\X$ then $FV(x) \equiv \{x\}$.
\item if $e = \lambda x.a$ then $FV(e)\equiv FV(a)\backslash\{x\}$.
\item if $e = a\ b$ then $FV(e)\equiv FV(a)\cup FV(b)$.
\item if $e$ is closed $FV(e)=\emptyset$.
\end{itemize}}

\Ex{}{}{\begin{itemize}
\item $e\equiv \lambda x.x$ then $FV(e) = \emptyset$.
\item $e\equiv \lambda x.y$ then $FV(e) = \{y\}$.
\end{itemize}}

\Def{Subsitution}{def:sub}{Given $x\in\X, a\in\Lambda$ the substitution of (all the) occurrences of $x$ in $e$ by $a$, denoted $e\brakets{a/x}$ is: \begin{itemize}
\item if $e\equiv y\in\X\backslash\{x\}$ then $y\brakets{a/x}\equiv y$ otherwise $x\brakets{a/x}\equiv a$.
\item $(\lambda y.e)\brakets{a/x}\equiv\lambda y.e\brakets{a/x}$
\item $(e\ f)\brakets{a/x}\equiv e\brakets{a/x}\ f\brakets{a/x}$.
\end{itemize} }

\Def{The $\betaar$ relation}{def:betaar}{The binary relation $\betaar$ over $\Lambda$ is $\betaar\subseteq\Lambda\times\Lambda$ such that $\betaar\equiv\{((\lambda x.a)\ b, a\brakets{b/x})|x\in\X,a\in\Lambda,b\in\Lambda\}$}

\Ex{}{}{\begin{itemize}
\item $(\lambda x.(\lambda y.y)\ a)\ b\betaar((\lambda y.y)\ a)\brakets{b/x} \equiv (\lambda y.y)\brakets{b/x}\ a\brakets{b/x} \equiv(\lambda y.y)\ a\brakets{b/x}$
\item $(\lambda x.y)\ a\betaar y$
\item Paradoxe de Russell : $(\lambda x. x\ x) (\lambda x.x\ x)\betaar (x\ x)\brakets{(\lambda x.x\ x)/x}$ or $(x\ x)\brakets{(\lambda y.y\ y)/x} \equiv (\lambda x. x\ x) (\lambda x.x\ x)$ modulo $\alphaeq$ (or exactly that if you consider the case before the "or"). Then it reduces to itself and the reduction does not terminate.
\end{itemize}}

Avec le dernier exemple, on peut voire que l'on a besoin de $\betaar\subseteq\beta_0\subseteq\beta\equiv\beta_0^*$ pour un certain $\beta_0$ et $\beta$ la fameuse $\beta$-réduction, $\beta\equiv\betaar^*$ aussi écrite $\betar$.

\Def{$\beta_0$-contraction}{def:b0contract}{Soit $a,b\in\Lambda$, on définit la relation $a\ \beta_0\ b$ comme ceci : \begin{itemize}
\item $x\ \beta_0\ x$
\item $(\lambda x.u)\ v\ \beta_0\ u\brakets{v/x}$
\item $(\lambda x.u)\ \beta_0\ (\lambda x.v)$ if $u\ \beta_0\ v$
\item $(u\ v)\ \beta_0\ (u'\ v)$ if $u\ \beta_0\ u'$ 
\item $(u\ v)\ \beta_0\ (u\ v')$ if $v\ \beta_0\ v'$ 
\end{itemize}}

\underline{Remarque :} Par induction structurelle on montre que $\beta_0$ est réflexive.

\Def{$\beta$-réduction}{def:betared}{La $\beta$-réduction est la clôture transitive de $\beta_0$, $\beta\equiv\beta_0^*$.}
\underline{Remarque :} Si $a,b\in\Lambda$ alors $a\ \beta\ b$ s'il existe $n\geq 0$ et $(e_k)_{0\leq k\leq n}$ tels que : \begin{itemize}
\item $a\equiv e_0$
\item $b\equiv e_n$
\item $\forall k<n, e_k\ \beta_0\ e_{k+1}$
\end{itemize}

\Def{$\lambda$-compatibilité}{def:lcompat}{Soit $\mathcal{R}$ une relation sur le $\lambda$-calcul, $\Lambda$. On fit que $\mathcal{R}$ est $\lambda$-compatible si : \begin{itemize}
\item elle est réflexive
\item si $a\ \mathcal{R}\ b$ et $c\ \mathcal{R}\ d$ alors $(a\ c)\ \mathcal{R}\ (b\ d)$
\item si $a\ \mathcal{R}\ b$ alors $\lambda x.a\ \mathcal{R}\ \lambda x.b$
\end{itemize}}

\Prop{}{def:betaRedCompat}{La $\beta$-réduction est la plus petite relation transitive $\lambda$-compatible contenant $\betaar$.}

\begin{proof}
\begin{itemize}
\item on vérifie d'abord $\betaar\subseteq\beta_0\subseteq\beta_0^*\equiv\beta$
\item maintenant on vérifie qu'elle est $\lambda$-compatible. \begin{itemize}
\item Elle est bien réflexive
\item Soit $a\ \beta\ b$ et $c\ \beta\ d$. On considère $(e_k)$ et $(f_k)$ associés. Considérons $g_k=\left\{\begin{array}{r l}
(e_k\ f_0) & \text{si $k\leq|e|$}\\
(e_{|e|}\ f_{k-|e|}) & \text{sinon}
\end{array}\right.$. Par définition de $\beta_0$ on obtient le résultat.
\item Soit $a\ \beta\ b$. On considère $(e_k)$ associé. Alors par définition de $\beta_0$ on a $\lambda x.e_k\ \beta\ \lambda x.e_{k+1}$. D'où $\lambda x.a\ \mathcal{R}\ \lambda x.b$
\end{itemize}
\item Soit $\mathcal{R}$ une autre relation $\lambda$-compatible et transitive contenant $\betaar$. Pour cela il suffit de vérifier que $\beta_0\subseteq\mathcal{R}$ et conclure par transitivité.
\end{itemize}
\end{proof}
\subsubsection{Propriétés essentielles de la $\beta$-réduction}
\underline{Remarque : } $(\Lambda,\beta_0)$ est un système de réduction abstrait (voir définition \ref{sysRedAbs}).

\Def{Forme Normale}{def:FormeNormale}{Soit $\mathcal{R}$ une relation binaire sur $\Lambda$. On dit que :
\begin{itemize}
\item $a$ est une forme normale (relativement à $\mathcal{R}$) s'il n'existe pas de $b\in\Lambda$ tel que $a\ \mathcal{R}\ b$
\item $a$ a une forme normale s'il existe une forme normale $b$ telle que $a\ \mathcal{R}^*\ b$.
\item $\mathcal{R}$ est normalisante si $\forall a\in\Lambda, a$ a une forme normale.
\end{itemize}}

\Def{Forme normale pour le lambda calcul}{def:FormeNormalLambda}{On dit que si $e\equiv\lambda x_1...x_n.\Delta\ u_1\ ...\ u_n$; soit $\Delta\in\mathcal{X}$ soit on dit que $\Delta$ est un $\beta$-redex.
\begin{itemize}
\item $e$ est une forme normale si $\Delta\in\mathcal{X}$ et $\forall i, u_i $ est une forme normale
\item $e$ est une forme normale de tête si $\Delta\in\mathcal{X}$
\item Si $e$ n'est pas une forme normale de tête ($\Delta$ est un $\beta$-redex) alors $\Delta$ est appelé redex de tête.
\end{itemize}}

\Def{Terme fortement normalisant}{}{$e\in\Lambda$ est fortement normalisant s'il n'existe pas de $\beta$-réduction infinie sur $e$.}

Soit $\mathcal{N}$ l'ensemble des termes fortement normalisant. Soit alors $\mathcal{N}_0=\{x\ u_1\ ...\ u_n|x\ u_1\ ...\ u_n \in\mathcal{N}\}\subseteq\mathcal{N}$.\\
Soit $Succ(e)=\{e'\in\Lambda|e\beta_0 e'\}$ l'ensemble des successeurs de $e$ pour $\beta_0$. Pour tout $e\in\Lambda$, c'est un ensemble fini.
\Lem{Koening}{lem:Koening}{Si un arbre est infini et cet arbre est a branchement fini alors il existe un chemin infini}

\begin{proof}
Exercice (facile)
\end{proof}

Si $e$ est fortement normalisant alors $\cup_{p\geq0}Succ^p(e)$ est fini.

Si $e\in\mathcal{N}$ on notera $l(e)$ la somme des longueurs de toutes les réductions issues de $e$.

\Lem{}{}{Sont immédiats:

\begin{itemize}
\item si $e\in\mathcal{N}$ alors $\lambda x.e\in\mathcal{N}$.
\item si $e\in\mathcal{N}$ et $e\beta e'$ alors $e'\in\mathcal{N}$.
\item si $e\in\Lambda$ et $Succ(e)\subseteq\mathcal{N}$ alors $e$ est fortement normalisant.
\item si $e\in\Lambda$ et $x\in\X$ on a $e\ x\in\mathcal{N}\Rightarrow e\in\mathcal{N}$
\end{itemize}}

\Ex{}{ex:normalisation}{\begin{itemize}
\item $\lambda x.x$ est une forme normale respectivement à $\beta_0$.
\item $\beta_0$ n'est pas normalisante. Par exemple $\Omega\equiv (\lambda x.x\ x)\ (\lambda x.x\ x)$ se réduit vers lui même.
\end{itemize}}

\Lem{}{}{Si $b\in\mathcal{N}$ et si $a\brakets{b/x}\ \overline{u} \in\mathcal{N}$ alors $(\lambda x.a)\ b\ \overline{u}\in\mathcal{N}$}

\begin{proof}
La preuve se fait par récurrence sur $l(b)+l(a\brakets{b/x}\ \overline{u})$. Il suffit de montrer que l'ensemble des successeurs pour $\beta_0$ de $(\lambda x.a)\ b\ \overline{u}$, $Succ((\lambda x.a)\ b\ \overline{u})\subseteq\mathcal{N}$
\end{proof}

\underline{Remarque : } L'hypothèse $b\in\mathcal{N}$ est inutile. $(\lambda x.\lambda y.t)\ \Omega\notin\mathcal{N}$ alors que $\lambda y.y\in\mathcal{N}$.

\begin{proof}
Le raisonnement procède par récurrence sur la parie $(l(b),l(a\brakets{b/x}\ \overline{u})$.

On regarde les successeurs $e'\in Succ(e)$ $e\ \beta_0\ e' $ si l'un des cas suivant est satisfait.\begin{itemize}
\item $(\lambda x.a)\ b\ \overline{u}\ \beta_0\ a\brakets{b/x}\ \overline{u}$
\item $(\lambda x.a)\ b\ \overline{u}\ \beta_0\ (\lambda x.a)\ b\ \overline{u'}$ tel que $u_i\ \beta_0\ u'_i$. Dans ce cas $a\brakets{b/x}\ \overline{u}\ \beta_0\ a\brakets{b/x}\ \overline{u'}$. De plus $l(a\brakets{b/x}\ \overline{u})>l(a\brakets{b/x}\ \overline{u'})$ donc par hypothèse on en deduit que $(\lambda x.a)\ b \overline{u'}\in\mathcal{N}$
\item $(\lambda x.a) b \overline{u}\ \beta_0\ (\lambda x.a) b' \overline{u}$ via $b\ \beta_0\ b'$
\item $(\lambda x.a) b \overline{u}\ \beta_0\ (\lambda x.a') b \overline{u}$ via $a\ \beta_0\ a'$
\end{itemize}
\end{proof} 

\Def{Confluence}{def:confluence}{Soit $\mathcal{R}$ une relation binaire sur $\Lambda$ si pour tous $a,b,c$ tels que $a\ \mathcal{R}^*\ b$ et $a\ \mathcal{R}^*\ c$ alors il existe $d\in\Lambda$ tel que $b\ \mathcal{R}^*\ d$ et $c\ \mathcal{R}^*\ d$.}
\begin{center}
\begin{tikzpicture}[>=latex]
\node	[]	at	(2,4)	{$a$};
\node	[]	at	(0,2)	{$b$};
\node	[]	at	(4,2)	{$c$};
\node	[]	at	(2,0)	{$d$};
\draw	[->] (1.8,3.8) --node[left] {$\mathcal{R}^*$} (0.2,2.2);
\draw	[->] (2.2,3.8) --node[right] {$\mathcal{R}^*$} (3.8,2.2);
\draw	[->, dashed] (0.2,1.8) --node[left] {$\mathcal{R}^*$} (1.8,0.2);
\draw	[->, dashed] (3.8,1.8) --node[right] {$\mathcal{R}^*$} (2.2,0.2);
\end{tikzpicture}
\end{center}

\Thm{Confulence de $\beta_0$}{thm:beta0Conflu}{$\beta_0$ est confluante.}

\begin{proof}
Cette preuve sera faite plus loin dans le cours.
\end{proof}

\Cor{}{cor:uniciteNormale}{Tout $\lambda$-terme a au plus une forme normale relativement à $\beta_0$}

\begin{proof}
Supposons deux forme normale distinctes $b$ et $c$ pour $a$ alors par confluence on a l'existence de $d$ tel que $b$ et $c$ s'y réduise ce qui est une contradiction.
\end{proof}

\subsubsection{Notion d'égalité sur $\Lambda$.}
\Def{$\lambda$-congruence}{def:lcongru}{Une $\lambda$-congruence et une relation d'équivalence $\lambda$-compatible.}

\Def{$\beta$-équivalence}{def:betaEq}{La $\beta$-équivalence sur $\Lambda$ est la relation binaire $=_\beta$ définie comme la clôture symétrique de $\beta$. On a $a=_\beta b$ s'il existe $(e_k)_{0\leq k\leq n}$ tel que $e_0=a$ et $e_n=b$ et pour tout $k<n$ $e_k\ \beta_0\ e_{k+1}$ ou $e_{k+1}\ \beta_0\ e_k$.}

\Thm{Church-Rosser}{thm:ChurchRosser}{Pour tous $a,b\in\Lambda$, $a=_\beta b$ ssi il existe $c\in\Lambda$ tel que $a\ \beta\ c$ et $b\ \beta\ c$.}
\begin{proof}
\begin{itemize}
\item La relation est clairement suffisante.
\item Pour la condition nécessaire, on introduit $\mathcal{R}\subseteq\Lambda^2$ définit par $a\ \mathcal{R}\ b$ ssi il existe $c\in\Lambda$ tel que $a\ \mathcal{R}\ c$ et $b\ \mathcal{R}\ c$. Elle est réflexive et symétrique. On vérifie encore qu'elle est transitive grâce à la confluence de $\beta$.
\begin{center}
\begin{tikzpicture}[>=latex]
\node	[]	at	(0,4)	{$a$};
\node	[]	at	(2,4)	{$b$};
\node	[]	at	(4,4)	{$c$};
\node	[]	at	(1,2)	{$d_1$};
\node	[]	at	(3,2)	{$d_2$};
\node	[]	at	(2,0)	{$e$};
\draw	[->] (1.8,3.8) --node[left] {$\mathcal{R}^*$} (1.2,2.2);
\draw	[->] (2.2,3.8) --node[right] {$\mathcal{R}^*$} (2.8,2.2);
\draw	[->] (0.2,3.8) --node[left]  {$\mathcal{R}^*$} (0.8,2.2);
\draw	[->] (3.8,3.8) --node[right]  {$\mathcal{R}^*$} (3.2,2.2);
\draw	[->, dashed] (1.2,1.8) --node[left] {$\mathcal{R}^*$} (1.8,0.2);
\draw	[->, dashed] (2.8,1.8) --node[right] {$\mathcal{R}^*$} (2.2,0.2);
\end{tikzpicture}
\end{center}

C'est donc une relation d'équivalence qui contient $\beta$. Par définition \ref{def:betaEq} on conclut à l'égalité (plus petite relation).
\end{itemize}
\end{proof}

\Thm{}{thm:betaEqpluspetite}{$=_\beta$ est la plus petite $\lambda$-congruence contenant $\betaar$}
\begin{proof}
Exercice
\end{proof}

\subsection{Paradoxe de Russel}
On compare la théorie naïve des ensembles et les lambda termes.
\begin{itemize}
\item les éléments correspondent à $e\in\Lambda$
\item une collection d'éléments $E$ (ensembles) correspondent à $\lambda x.e$
\item la relation d'appartenance $e\in E$ correspond à $E e$
\item l'égalité dans l'ensemble correspond à $=_\beta$.
\end{itemize}

Soit $R$ la collection des ensembles qui ne s'appartiennent pas eux même. Si c'est un ensemble. $R\in R \Leftrightarrow \neg (R\in R)$.

Il vient si $n$ est un $\lambda$-terme pour la négation $R\equiv \lambda x.n\ (x\ x)$. Donc $R\ R \betaar n\ (R\ R)$.

Soit $\Omega\equiv (\lambda x.x\ x)\ (\lambda x.x\ x)$.

Soit $Y = \lambda f(\lambda x.f\ (x\ x))\ (\lambda x.f\ (x\ x)).$

Ces termes n'admettent pas de forme normale et se dérivent infiniment.

\subsection{Parties saturées de $\Lambda$}
\Def{Partie saturée}{def:partSaturee}{Soit $S\subseteq\Lambda$, un ensemble de $\lambda$-termes. On dit que $S$ est saturée si elle satisfait les conditions suivantes : \begin{itemize}
\item $\mathcal{N}_0\subseteq S\subseteq\mathcal{N}$
\item si $e\in S$ et $e\ \beta_0^*\ e'$ alors $e'\in S$
\item si $e\in\Lambda$ et $e$ n'est pas une $\lambda$-abstraction et si $Succ(e)\subseteq S$, alors $e\in S$.
\end{itemize}

On note $(\Lambda)$ l'ensemble des parties saturées de $\Lambda$.}

\Prop{}{prop:partSat}{On a les propriétés suivantes :
\begin{itemize}
\item $\mathcal{N}_0$ est saturée.
\item $\mathcal{N}$ est saturée.
\item Si $X$ et $Y$ sont des parties saturées alors $X\rightarrow Y\equiv\{e\in\Lambda|\forall a\in X, e\ a\in Y\}$ est elle-même saturée.
\end{itemize}}

\begin{proof}
On démontre les points dans l'ordre :
\begin{itemize}
\item Le premier point est en exercice.
\item Pour le deuxième points il suffit de vérifier la dernière propriété de la définition.

En clair soit $e\in\Lambda$ qui n'est pas une $\lambda$-abstraction et tel que $Succ(e)\subseteq\mathcal{N}$. On procède par induction structurelle sur $e$ :
\begin{itemize}
\item si $e\in\X$ c'est trivial
\item si $e\equiv e_0\ a$ avec $Succ(e)\subseteq\mathcal{N}$. Alors 
\subitem $e\ \beta_0\ e_0'\ a$ avec $e_0\ \beta_0\ e_0'$
\subitem $e\ \beta_0\ e_0\ a'$ avec $a\ \beta_0\ a'$
\subitem $e\ \beta_0\ e_1\brakets{a/x}$ avec $e_0\equiv\lambda x.e_1$

Les successeurs sont dans $\mathcal{N}$ donc on a encore $e\in\mathcal{N}$.
\end{itemize}
\item Soit $X,Y\in(\Lambda)$. Montrons que $X\rightarrow Y\in(\Lambda)$.
\begin{itemize}
\item On a $\mathcal{N}_0\subseteq X\rightarrow Y$. Soit $x\ \overline{u}\in\mathcal{N_0}$. Soit $a\in X\subseteq\mathcal{N}$. Alors $x\ \overline{u}\ a\in\mathcal{N}_0\subseteq Y$. D'où le résultat. 

On a aussi $X\rightarrow Y\subseteq\mathcal{N}$, car sinon $e\ a\in Y$ n'est pas fortement normalisant.
\item La deuxième propriété est facile. Soit $e\in X\rightarrow Y$ et $e\ \beta_0\ e'$. Alors soit $a\in X$ alors $(e\ a)\ \beta_0\ (e'\ a)$ et $(e\ a)\in Y$. Or $Succ(e\ a)\subseteq Y$, d'où $e'\ a\in Y$.
\item Soit $e$ qui n'est pas une abstraction telle que $Succ(e)\in X\rightarrow Y$. Soit $a\in X$. Il s'agit de montrer que $e\ a\in Y$. Il suffit de vérifier que $Succ(e\ a)\in Y$ et on fini la démonstration par récurrence sur $l(a)$.
\end{itemize}
\end{itemize}
\end{proof}

\section{Calcul propositionnel (cf. notes de P.Audebaud)}
\subsection{Éléments de langage (informel)}
On parle ici de théorie de la démonstration (prouvabilité) et la théorie des modèles (validité, vérité). On parle donc du lien entre correction (ce qui est prouvé est vrai) et complétude (ce qui est vrai est prouvable). 

On se pose la question du vrai. En logique classique tout est énoncé est soit vrai soit faux, c'est l'axiome du tiers-exclu. Cependant en informatique, tout énoncé n'est pas nécessairement décidable. En logique intuitionniste on s'intéresse aux éléments de la preuve. Le faux n'est pas le problème en lui même n'est pas le problème mais l'usage qui en est fait.

On s'intéresse en particulier à la logique intuitionniste.

\Def{Proposition}{def:prop}{Les formules du calcul propositionnel sont définies par la grammaire suivante :
\[A::=X|\top|\bot|A\Rightarrow B|A\wedge B| A\vee B\cancel{|\neg A}\]
On dira alors que $A$ engendré par cette grammaire est une proposition.}

On portera des jugement sur ces énoncés (propositions) du genre "$A$ $true$". On aura aussi des des jugements hypothétiques $A_1\ true,..., A_n\ true\vdash B\ true$. On utilise des règles de déduction du genre
\[\rRule{R}{\text{Prémisse}_1\ ...\ \text{Prémisse}_n}{\text{Conclusion}}\]

On utilisera plusieurs règles (voir section \ref{reglededuc})

On a aussi quelques règles suspectes. L’affaiblissement :
\[\rRule{W}{\Delta \vdash B\ true}{\Delta,A\vdash B\ true}\]
La contraction :
\[\rRule{C}{\Delta,A,A\vdash}{\Delta,A\vdash B}\]
Permutation : 
\[\rRule{P}{\Delta\vdash B,\ \Gamma \text{ permutation de $\Delta$}}{\Gamma\vdash B}\]
Réflexivité :
\[\rRule{R}{}{A\vdash A}\]
Affaiblissement :
\[\rRule{\text{Aff}}{\Delta\vdash B}{\Delta,A\vdash B}\]
Transitivité :
\[\rRule{T}{A \text{ True}\ \ \ A\vdash B}{B \text{True}}\]

\subsection{Règles de déduction de la logique intuitionniste}
Pourra être complété par l'annexe de Philippe Audebaud
\label{reglededuc}
\subsubsection{Conjonction}
On a la formation
\[\rRule{\wedge_F}{A\ prop\ \ \ B\ prop}{A\wedge B\ prop}\]
On a l'introduction
\[\rRule{\wedge_I}{A\ true\ \ \ B\ true}{A\wedge B\ true}\]
On a l'élimination
\[\begin{array}{r l}\rRule{\wedge_E}{A\wedge B\ true}{A\ true}&\rRule{\wedge_E}{A\wedge B\ true}{B\ true}\end{array}\]
\subsubsection{Le vrai $\top$}
On a formation et introduction
\[\begin{array}{r l}\rRule{\top_F}{}{\top\ prop}&\rRule{\top_I}{}{\top\ true}\end{array}\]
On a pas d'élimination car on ne peut rien sortir du vrai.

Le vrai correspond aussi au cas limite d'une conjonction vide.
\subsubsection{L'implication}
On a la formation 
\[\rRule{\Rightarrow_F}{A\ prop\ \ \ B\ prop}{A\Rightarrow B\ prop}\]
On a l'introduction : 
\[\rRule{\Rightarrow_I}{\Delta,A\vdash B}{\Delta\vdash A\Rightarrow B}\]
On a l'élimination :
\[\rRule{\Rightarrow_E}{A\Rightarrow B\ true\ \ \ A\ true}{B\ true}\]
On a cependant aussi une particularité, la règle suivante est admissible (on peut la dérivée de la règle d’affaiblissement):
\[\rRule{?}{\Delta\vdash A\Rightarrow B}{\Delta,A\vdash B}\]
C'est exactement l'inverse de l'introduction. Cette règle est \underline{inversible}.

\subsubsection{Le faux $\bot$}
On a formation :
\[\rRule{\bot_F}{}{\bot\ prop}\]

On a cependant pas l'introduction, on ne veux pas dire que faux et vrai trivialement.
On a cependant l'élimination, faux prouve tout :
\[\rRule{\bot_E}{\bot\ true}{A\ true}\]

Le vrai correspond aussi au cas limite d'une conjonction vide.

\subsubsection{La négation}
On rejette le tiers-exclu. Pour gérer l’inconsistance on défini $\neg A\equiv A\Rightarrow\bot$. Alors :
\[\rRule{\Rightarrow_E}{A\ true\ \ \ \neg A\ true}{\bot}\]
On renégocie donc l'usage du faux.

\subsubsection{Disjonction}
On a la formation
\[\rRule{\vee_F}{A\ prop\ \ \ B\ prop}{A\vee B\ prop}\]
On a l'introduction
\[\begin{array}{r l}\rRule{\vee_{Ig}}{A\ true}{A\vee B\ true}&\rRule{\vee_{Ig}}{B\ true}{A\vee B\ true}\end{array}\]
On a l'élimination
\[\rRule{\vee_E}{A\vee B\ true\ \ \ A\ true\vdash C\ true\ \ \ B\ true\vdash C\ true}{C\ true}\]

\subsection{Types simples}
Une proposition est abstraite en un \underline{type}, élément de l'algèbre suivante :\[T::=X\in\X|T\rightarrow T|...\] avec $\X$ un ensemble dénombrables de variables.

Pour un $\lambda$-terme, t on va le mettre en relation avec un type $T$, une relation binaire $t:T$ avec signification $T\ true$. Alors $t$ sera un \underline{temoin}. On pourra aussi voir les types comme des ensembles, ils seront vrais s'ils sont habités (non vides). Alors $T_1\ true,...,T_n\ true\vdash T\ true$ donnera $t_1:T_1,...,t_n:T_n\vdash t:T$. On aura alors :
\[\begin{array}{r c l}\rRule{Hyp}{x:T\in\Delta}{\Delta\vdash x:T}&\rRule{\rightarrow_I}{\Delta,x:S\vdash t:T}{\Delta\vdash \lambda x.t:S\rightarrow T}&
\rRule{\rightarrow_E}{\Delta\vdash t:S\rightarrow T\ \ \ \Delta \vdash s:S}{\Delta\vdash (t\ s):T}
\end{array}\]

On se pose alors la question du type de $\lambda x.x$, $\lambda xy.x$, $\lambda xy.y$, $\lambda x.x\ x$.

\Ex{(Exercice)}{}{Montrer qu'il existe $S$ tel que pour tout $X,Y,Z\in\X$, $\vdash S:(X\rightarrow Y\rightarrow Z)\rightarrow (X\rightarrow Y)\rightarrow (X\rightarrow Z)$.} 

\Def{Variables libre d'un contexte}{def:varlibrecontext}{On définit:

\begin{itemize} 
\item $FV(\emptyset)=\emptyset$
\item $FV(\Delta, x:T)=FV(\Delta,x)$
\end{itemize}}

\Lem{}{lem:preuvedetypeetvarlibres}{Si $\Delta\vdash t:T$ alors $FV(t)\subseteq FV(\Delta)$}

\begin{proof}
Exercice
\end{proof}

On peut alors introduire la règle d'affaiblissement :
\[\rRule{\text{Aff}}{\Delta\vdash t:T\ \ \ x\notin FV(\Delta)}{\Delta,x:S\vdash t:T}\]
\Lem{Affaiblissement}{lem:aff}{Si $\Delta\vdash t:T$ et si $\Delta\subseteq\Delta'$ alors $\Delta'\vdash t:T$.}

\begin{proof}
Par induction sur la dérivation principale.

Le seul cas problématique est $\Rightarrow_I$. On pourra grâce à $\alphaeq$ supposer que $x\notin FV(\Delta')$.
\end{proof}

\Thm{Condition nécessaire au typage}{thm:CNType}{Si $\Delta\vdash t:T$ alors $t$ est fortement normalisant.}

\begin{proof}
La preuve se fait en deux parties, poser les notions générales et l'adaptation ou $\lambda$ calcul typé.
\end{proof}

\subsection{Correspondance de Curry-Howard.}
CF notes en ligne.

\subsection{Normalisation forte pour $\lambda_\rightarrow$}
\Thm{SN}{}{Si $\Delta\vdash_{\lambda_\rightarrow}e:T$ alors $e\in\mathcal{N}$.}

Pour prouver cela on interprète les types comme des parties saturés. On utilisera un lemme d'adéquation et on confluera le théorème comme un corollaire.

\Def{}{}{Soit $\rho\in\mathcal{V}\rightarrow(\Lambda)$ ($\mathcal{V}$ est la collection des variables de types). On définit l'interprétation d'un terme $T$ selon $\rho$, noté $\llbracket T\rrbracket\rho$ est définit par :\begin{itemize}
\item si $T\in\mathcal{V}$ alors $\llbracket T\rrbracket\rho\equiv\rho(T)$
\item si $T\equiv U\rightarrow V$ alors $\llbracket T\rrbracket\rho\equiv\llbracket U\rrbracket\rho\rightarrow\llbracket V\rrbracket\rho$
\end{itemize}}

Par la proposition \ref{prop:partSat} $\llbracket T\rrbracket\rho$ est une partie saturée et $\rho$ existe. 

Remarquons que $\llbracket T\rrbracket\rho$ ne dépend que de $\rho_{|FT(T)}$.

\Def{}{}{Soit $x_1,...x_n\in\X$ et $t_1,...,t_n\in\Lambda$ la substitution $\sigma\equiv\brakets{t_1/x_1,...,t_n/x_n}$ donne lieu à $\sigma(t)$ pour $t\in\Lambda$ comme le $\brakets{\cdot/\cdot}$ définit précédemment.}

\Prop{}{}{Soit $\rho$ une interprétation de types et $\Delta\vdash_{\lambda_\rightarrow}t:T$; Soit $\sigma$ une substitution telle que $dom(\sigma)\subseteq FV(\Delta)$, telle que pour tout $x:S\in\Delta$, $\sigma(x)\in\llbracket S\rrbracket\rho$ on a $\sigma(t)\in\llbracket T\rrbracket\rho$.}

\begin{proof}
On prouve cela par induction sur la hauteur de la dérivation. Le seul cas intéressant est le cas de $(\rightarrow_I)$.
\[\rRule{\rightarrow}{\Delta,x:U\vdash a:V}{\Delta\vdash t:U\rightarrow V}\]
avec $t\equiv\lambda x.a$. Soit $\sigma$ de domaine dans $FV(\Delta)$. Montrons que si pour tout $x:S\in\Delta$, $\sigma(x)\in\llbracket S\rrbracket\rho$ on a $\sigma(t)\in\llbracket T\rrbracket\rho$. avec $T=U\rightarrow V$. Par définition cela revient à montrer que pour tout $b\in\llbracket U\rrbracket\rho$, $\sigma(\lambda x.a)\ b\in\llbracket V\rrbracket\rho$.

On peut faire en sorte que $x$ ne soit une nouvelle variable. Considérons alors $\sigma'\equiv\brakets{t_1/x_1,...,t_n/x_n,b/a}$. On a alors $\sigma(\lambda x.a)\ b\equiv\sigma'(a)$. On peut appliquer l'hypothèse d'induction sur $\sigma'$. Finalement $(\lambda x.\sigma(a))\ b\ \beta_0\ \sigma'(a)\in\llbracket V\rrbracket\rho$ avec $b\in\llbracket U\rrbracket\rho\subseteq\mathcal{N}$. Donc $(\lambda x.\sigma(a))\ b\in \llbracket V\rrbracket\rho$.

En résumé $\lambda x.\sigma(a)\equiv\sigma(\lambda x.a)\in\llbracket U\rightarrow V\rrbracket\rho$ et $\sigma(t)\equiv\lambda x.\sigma(t_0)$. Si $t\equiv a\ b$ alors $\sigma(t)\equiv \sigma(a)\ \sigma(b)$.
\end{proof}

\section{Polymorphisme}
Jusque là on peut résumer à la situation au tableau suivant :
\begin{center}
\begin{tikzpicture}
\node at (0,6) {Programmation};
\node at (0,5.5) {$\lambda$-calcul};
\node at (0,5) {$\lambda$-calcul enrichi};
\node at (0,4) {Calcul de combinateurs};

\node at (3,6) {Théorie des types};
\node at (3,5.5) {$\lambda_\rightarrow$};
\node at (3,5) {$\lambda_{\rightarrow,\times,\bot,\top,...}$};
\node at (3,4.5) {$\lambda_\alpha$};

\node at (6,6) {Raisonnement};
\node at (6,5.5) {$NT(\Rightarrow)$};
\node at (6,5) {$NP$};
\node at (6,4.5) {$NK$};
\node at (6,4) {Systèmes à la Hilbert (1900)};
\end{tikzpicture}
\end{center}

On va introduire le système $F$ en se séparant dans un premier temps du raisonnement puis on quittera aussi le point de vue programmation pour garder la théorie des types comme cœur (partie suivante).

\subsection{Motivations}
Prenons quelques exemples : 
\begin{itemize}
\item L'identité : pour tout type $T$, dans $\lambda_\rightarrow$, on a alors $\vdash \lambda x.x:T\rightarrow T$. On a rien a gagner à fixer le type $T$. Ce qui est important c'est que ça soit la même chose des deux côtés. On aimerait que l'identité soit "polymorphe", donner à l'identité un type polymorphe du genre $\vdash \lambda x.x:\forall T, T\rightarrow T$.
\item Entier de Church : par exemple, $\overline{2}\equiv\lambda xf. f\ (f\ x)$. On a donc dans $\lambda_\rightarrow$, $\vdash\overline{2}:A\rightarrow (A\rightarrow A)\rightarrow A$. De même cela est vrai pour tout type $A$, il faudrait donc aussi un type polymorphe.
\item $\Delta\equiv\lambda x.x\ x$. Ce terme est en forme normale et il est clos. Supposons qu'on puisse lui donner une type $T$, par inversion de $\rightarrow_I$ on a que $T=U\rightarrow V$ et $x:U\vdash x\ x:V$ puis par inversion de $\rightarrow_E$, $x:U\vdash x: W\rightarrow V$ et $x:U\vdash x: W$, puis $U\equiv W\rightarrow V$ et $U\equiv W$ donc $W\equiv W\rightarrow V$ ce qui n'a pas de solution, a priori, typiquement si $x$ est polymorphe, on pourrait arriver à typer $\Delta$.
\end{itemize}

\underline{Observations :}\begin{itemize}
\item On veut donner à un terme "plusieurs types" d'un seul coup.
\subitem en C on a les templates,
\subitem en OCaml on a les types $'a$.
\item On peut avoir besoin de gérer plusieurs occurrences d'une même variable.

\item observation de J.Rupolds (74)

\item introduit par JY.Girard (70) (cadre logique). 
\end{itemize}

\subsection{Système $F$ à la Church}
On veut une généralisation (d’abstraction) sur les types :
\[T::=X\in\X|T\rightarrow T|\forall X,T\]
Il nous faudra aussi une règle d'instanciation de types : $\forall X.T \leadsto T\brakets{S/X}$.

On va donc avoir une conséquence sur les termes:
\[t::= x\in\mathcal{X}|\lambda x.t| t\ t|\Lambda X.t| t\ T\]

Il nous faudra aussi une règle $\forall_I$ et $\forall_E$.

\[\begin{array}{r l}
\rRule{\forall_I}{\Delta\vdash t:T\ \ X\notin FT(\Delta)}{\Delta\vdash \Lambda X.t:\forall X,T} & \rRule{\forall_E}{\Delta\vdash t:\forall X,T}{\Delta\vdash t\brakets{S/X}: T\brakets{S/X}}
\end{array}\]


Remarquons qu'il faut de la règle $(\rightarrow_I)$ doivent encore porter l'information sur les types ($\lambda x^S...$).

Revenons donc aux exemples, \begin{itemize}
\item Pour l'identité : $\vdash_{Church}\Lambda X.\lambda x^X.x:\forall X,X\rightarrow X$
\item Pour les entiers de Church : $\vdash_{Church}\Lambda X.\lambda x^X.\lambda f^{X\rightarrow X}. f\ (f\ x):\forall X, X\rightarrow (X\rightarrow X)\rightarrow X$.
\item Pour $\lambda x. x\ x$. On a:

\[\rRule{\rightarrow_I}{\rRule{}{\rRule{}{}{x:\forall X,S\vdash (x\ U):(V\rightarrow V)\rightarrow W}\ \ \ \rRule{}{}{x:\forall X,S\vdash x\ V:V\rightarrow V}}{x:\forall X,S\vdash x\ U\ (x\ V): W}}{\vdash \lambda x^{\forall X,S}. x\ U\ (x\ V):(\forall X,S)\rightarrow W}\]

Prenons alors $S\equiv X\rightarrow X$ et on obtient:
\[\rRule{\rightarrow_I}{\rRule{}{\rRule{}{}{x:\forall X,(X\rightarrow X)\vdash (x\ (Y\rightarrow Y)):(Y\rightarrow Y)\rightarrow (Y\rightarrow Y)}\ \ \ \rRule{}{}{x:\forall X,(X\rightarrow X)\vdash x\ Y:Y\rightarrow Y}}{x:\forall X,X\rightarrow X\vdash \Lambda Y.x\ (Y\rightarrow Y)\ (x\ Y): \forall Y,(Y\rightarrow Y)}}{\vdash \lambda x^{\forall X,X\rightarrow X}. \Lambda Y.x\ (Y\rightarrow Y)\ (x\ Y):(\forall X,X\rightarrow X)\rightarrow (\forall Y,Y\rightarrow Y)}\]
\end{itemize}

\subsection{Système $F$ à la Curry}
On utilise des $\lambda$-termes purs et les même types que dans le système à la Church. On a toujours besoin des règle d'introduction et d'élimination de $\forall$.

\[\begin{array}{r l}
\rRule{\forall_I}{\Delta\vdash t:T\ \ \ X\notin FT(\Delta)}{\Delta\vdash t:\forall X,T} & \rRule{\forall_E}{\Delta\vdash t:\forall X,T}{\Delta\vdash t: T\brakets{S/X}}
\end{array}\]

On aimerait donc comme précédemment que $\vdash \lambda x.x\ x: (\forall X,X\rightarrow X)\rightarrow (\forall X,X\rightarrow X)$.

\subsection{Aspects dynamiques}
\subsubsection{A la Church}
\begin{itemize}
\item $(\lambda x^T.a)\ b\betaar a\brakets{b/x}$
\item $(\Lambda X.t)\ S\betaar t\brakets{S/X}$.
\end{itemize}
\subsubsection{A la Curry}
Ici rien à signaler de très précis puisque les termes ne sont pas changés.

\subsection{Propriétés méta du système $F$}
\begin{itemize}
\item expressivité
\item CR (Church-Rosser), SN (strong normalization), SR (subject reduction)
\item Propriété de décidabilité. 
\end{itemize}
\begin{center}
\begin{tikzpicture}
\node at (0,6) {Propriété};
\node at (0,5.5) {CR};
\node at (0,5) {SR};
\node at (0,4.5) {SN};

\node at (5,6) {$F$ pour Church};
\node at (5,5.5) {x};
\node at (5,5) {Facile};
\node at (5,4.5) {cf TD};

\node at (10,6) {$F$ pour Curry};
\node at (10,5.5) {déjà fait};
\node at (10,5) {plus dur};
\node at (10,4.5) {cf TD, àpartir de $\lambda_\rightarrow$};
\draw [->] (9,5.5) -- (6,5.5);
\end{tikzpicture}
\end{center} 
Dans les deux systèmes $F$ on a les lemmes suivant : 

\Lem{}{lem:restrictFV}{Si $\Delta\vdash t:T$ et $\Delta'$ contexte de typage tel que $\Delta_{|FV(t)}=\Delta'_{|FV(t)}$ alors $\Delta'\vdash t:T$.}
\Lem{}{lem:remplVarType}{Si $\Delta\vdash t:T$ alors pour tout $S$ et toute variable de type $X$, $\Delta\brakets{S/X}\vdash t\brakets{S/X}:T\brakets{S/X}$.}
\Lem{}{lem:particularisation}{Si $\Delta,x:S\vdash t:T$ et $\Delta\vdash s:S$ alors $\Delta\vdash t\brakets{s/x}:T$}

\subsubsection{Propriétés de $F$-Church}
\Prop{SR}{prop:ChurchSR}{Si $\Delta\vdash_{Church} t:T$ et $t\rightarrow t'$ alors $\Delta\vdash_{Church} t':T$}
\begin{proof}
En exercice
\end{proof}

Pour rappel, la relation $\rightarrow$ est l'analogue de $\beta_0$.

\Thm{SN}{thm:ChurchSN}{Si $\Delta\vdash_{Church}t:T$ alors $t$ est fortement normalisant.}

\begin{proof}
CF fiche d'exercice de la semaine 7. Elle basée sur le résultat pour $\lambda_\rightarrow$
\end{proof}

\Prop{Confluence faible}{}{Si $\Delta\vdash_{Church}t:T$ et si $t\rightarrow t_1$ et $t\rightarrow t_2$ alors il existe $t_3$ tel que $t_i\rightarrow^*t_3$ pour $i=1,2$}

\Cor{Confluence}{cor:Church:Confl}{La relation $\rightarrow$ est confluante sur les termes bien typés.}

\begin{proof}
On s’appuie sur le résultat SN et la confluence faible.
\end{proof}

\subsubsection{Propriétés de $F$-Curry}
On peut établir le résultat suivant.

\Thm{SR}{prop:CurrySR}{Si $\Delta\vdash_{Curry} t:T$ et $t\ \beta_0\ t'$ alors $\Delta\vdash_{Curry} t':T$}

Ce dernier résultat est vrai mais sa preuve nécessite quelques détours.

\paragraph{Système alternatif}
On introduit la notion de \underline{séquence} de type $\Delta\vdash T_0,...,T_n$ séquence avec les règles suivantes :
\[\rRule{Ax}{}{\Delta\vdash_0 T\text{ seq}}\]
\[\rRule{Gen}{\Delta\vdash_n T_0,...,T_n\text{ seq}\ \ X\notin FT(\Delta)}{\Delta\vdash_{n+1}T_0,...,T_n,\forall X.T_n \text{ seq}}\]
\[\rRule{Inst}{\Delta\vdash_n T_0,...,T_n\text{ seq}\ \ T_n\equiv\forall X.T}{\Delta\vdash_{n+1}T_0,...,T_n,T\brakets{S/X} \text{ seq}}\]
\[\rRule{Hyp}{x:T\in\Delta}{\Delta\vdash_0 x:T}\]
\[\rRule{\rightarrow_I}{\Delta,x:S\vdash_n t:T}{\Delta\vdash_0\lambda x.t:S\rightarrow T}\]
\[\rRule{\rightarrow_E}{\Delta\vdash_p e:S\rightarrow T\ \ \Delta\vdash_q s:S}{\Delta\vdash_0 e\ s:T}\]
\[\rRule{Sub}{\Delta\vdash_0 t:T\ \ \Delta\vdash_nT_0,...,T_n\text{ seq}}{\Delta\vdash_n t:T_n}\]

\Prop{}{prop:equivCurrySeq}{$\Delta\vdash_{Curry}t:T$ si et seulement si il exists $n\in\N$ tel que $\Delta\vdash_nt:T$}

\begin{proof}
Pour les deux sens on procède par induction. Exercice.
\end{proof}

\paragraph{Exercice} Si $\Delta\vdash_pt:T$ et $\Delta\vdash_qT_0,...,T_n\text{ seq}$ avec $T_0\equiv T$ alors $\Delta\vdash_{p+q-1}t:T_q$
\paragraph{Exercice} Si $\Delta\vdash_nT_0,...,T_n\text{ seq}$ avec $T_0\equiv U\rightarrow V$ et $T_n\equiv A\rightarrow B$ alors il existe $\overline{X}\subseteq\X$ et $\overline{S}$ une séquence de la même longueur tels que $A\equiv U\brakets{\overline{S}/\overline{X}}$ et $B\equiv V\brakets{\overline{S}/\overline{X}}$

\Lem{}{}{Si $\Delta\vdash_nt:T$ alors $\Delta\brakets{S/X}\vdash_nt:T\brakets{S/X}$}
\begin{proof}
Facile, exercice
\end{proof}
\Lem{}{}{Si $\Delta,x:S\vdash_n t:T$ et $\Delta\vdash_r s:S$ alors il existe $n'\in\N$ tel que $\Delta\vdash_{n'}t\brakets{s/x}:T$}
\begin{proof}
Considérons le cas où $t$ est une variable. \begin{itemize}
\item Soit $n=0$ et $\rRule{Hyp}{}{\Delta,x:S\vdash_0 t:T}$
\subitem si $t\equiv x$ $S\equiv T$. Par ailleurs $\Delta\vdash_r s:T$ donc $\Delta\vdash_r t\brakets{s/x}:T$
\subitem si $t\not\equiv x$ alors $t:T\in\Delta$ et $\rRule{Hyp}{}{\Delta\vdash_0 t:T}$
\item Soit $n>0$ et alors $\rRule{Sub}{\Delta\vdash_0 t:T_0\ \ \Delta\vdash_nT_0,...,T_n\text{ seq}}{\Delta\vdash_n t:T_n}$. Par l'hypothèse d'induction il existe $n''\in\N$ tel que $\Delta\vdash_{n''}t:T_0$ On conclut alors que $\Delta\vdash_{n+n''-1}t:T_n$ par le premier exercice ci-dessus.
\end{itemize}
On procède de même pour les autres cas où $t$ n'est pas une variable.\end{proof}

\Lem{}{}{Si $\Delta\vdash_n(\lambda x.A)\ b:T$ alors il existe $n'\leq 0$ tel que $\Delta\vdash_{n'}a\brakets{b/x}:T$}
\begin{proof}
On se limite au cas où $n=0$ on a:
\[\rRule{\rightarrow_E}{\Delta\vdash_p\lambda x.a:S\rightarrow T\ \ \Delta\vdash_q b:S}{\Delta\vdash_0 (\lambda x.a)\ b:T}\]

\[\rRule{}{\rRule{}{\rRule{}{\Pi}{\Delta,x:U\vdash_r a:V}}{\Delta\vdash_0\lambda x.a:U\rightarrow V}\ \ \Delta\vdash_p F_0,...,F_p\text{ seq}}{\Delta\vdash_p\lambda x.a:S\rightarrow T}\]

Avec $F_0\equiv U\rightarrow V$ et $F_p\equiv S\rightarrow T$. Par le deuxième exercice ci-dessus on obtient les séquences $\overline{X}$ et $\overline{S}$ correspondantes.

Par ailleurs $\rRule{}{\Delta\vdash_0 b:S\ \ \Delta\vdash_q S_0,...,S_q}{\Delta\vdash_q b:S}$ avec $S_q\equiv S$. On en déduit que $\Delta\brakets{\overline{S}.\overline{X}},x:U\brakets{\overline{S}/\overline{X}\vdash_r a:V\brakets{\overline{S}/\overline{X}}}$ puis que $\Delta,x:S\vdash_r a:T$.

Finalement avec de plus $\Delta \vdash_q b$ on en déduit le résultat.
\end{proof}

\Prop{SR pour le séquencement}{prop:CurrySRseq}{Si $\Delta\vdash_n t:T$ et $t\ \beta_0\ t'$ alors $\Delta\vdash_n t'$}

\begin{proof}
On a $\rightarrow_\beta\subseteq\beta_0$. On peut conclure dessus. Il suffit alors de revenir sur les autres constructeurs qui définissent $\beta_0$.
\end{proof}

On peut maintenant revenir sur le théorème \ref{prop:CurrySR}. On conclut avec la proposition \ref{prop:equivCurrySeq}.
\end{document}
